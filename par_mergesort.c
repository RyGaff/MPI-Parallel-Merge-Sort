/*
 * mergesort.c
 *
 * CS 470 Project 3 (MPI)
 * Parallelized version.
 * This work abides by the JMU Honor Code
 *
 * Name(s): Ryan Gaffney, Jacob Gottschalk
 *
 * FULL ANALYSIS:
 * https://w3stu.cs.jmu.edu/gottscji/p3_analysis.pdf
 */

#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include <mpi.h>

// histogram bins
#define BINS 10

// maximum random number
#define RMAX 1000

// limit debug output
#define MAX_DEBUG_COUNT 32

// timing macros
// uses MPI timings and MPI barriers before starting
#define START_TIMER(NAME) \
    MPI_Barrier(MPI_COMM_WORLD); \
    double NAME##_time = MPI_Wtime();

// Stop timer and reduces the max time to p0
// interior block so that temp variable does not remain in scope
#define STOP_TIMER(NAME) \
    NAME ## _time = MPI_Wtime() - (NAME ## _time); \
    { \
         double tmp = 0.0; \
	 MPI_Reduce(& NAME ## _time, &tmp, 1, MPI_DOUBLE, MPI_MAX, 0, MPI_COMM_WORLD); \
	 NAME ## _time = tmp; \
    }
#define GET_TIMER(NAME) (NAME##_time)

// "count_t" used for number counts that could become quite high
typedef unsigned long count_t;

int *nums;            // random numbers
count_t  global_n;    // global "nums" count
count_t  shift_n;     // global left shift offset
count_t *hist;        // histogram (counts of "nums" in bins)

int my_rank;          // MPI process rank
int nprocs;           // number of MPI processes
count_t local_n;      // number of ints per process

/*
 * Parse and handle command-line parameters. Returns true if parameters were
 * valid; false if not.
 */
bool parse_command_line(int argc, char *argv[])
{
    // read command-line parameters
    if (argc != 3) {
        if (my_rank == 0) printf("Usage: %s <n> <shift>\n", argv[0]);
        return false;
    } else {
        global_n = strtol(argv[1], NULL, 10);
        shift_n  = strtol(argv[2], NULL, 10);
    }

    // check shift offset
    if (shift_n > global_n) {
        if (my_rank == 0) printf("ERROR: shift offset cannot be greater than N\n");
        return false;
    }

    return true;
}

/*
 * Allocate and initialize number array and histogram.
 */
void initialize_data_structures()
{
    // initialize local data structures
    nums = (int*)calloc(global_n, sizeof(int));
    if (nums == NULL) {
        fprintf(stderr, "Out of memory!\n");
        exit(EXIT_FAILURE);
    }
    hist = (count_t*)calloc(BINS, sizeof(count_t));
    if (hist == NULL) {
        fprintf(stderr, "Out of memory!\n");
        exit(EXIT_FAILURE);
    }
}

/*
 * Compares two ints. Suitable for calls to standard qsort routine.
 */
int cmp(const void* a, const void* b)
{
    return *(int*)a - *(int*)b;
}

/*
 * Print contents of an int list.
 */
void print_nums(int *a, count_t n)
{
    for (count_t i = 0; i < n; i++) {
        printf("%3d ", a[i]);
    }
}

/*
 * Print contents of a distributed int list by first gathering to rank 0.
 * Prints extra string char *before and char *after respectively.
 */
void print_distributed_nums(int *arr, int size, const char *before, const char *after)
{
    int tmp[size*nprocs];
    // gather nums to process 0
    MPI_Gather(arr, size, MPI_INT,
               tmp, size, MPI_INT, 0, MPI_COMM_WORLD);
    // process 0 prints
    if (my_rank == 0) {
        printf("%s", before);
        for (int i = 0; i < size*nprocs; i++) {
            printf("%3d ", tmp[i]);
        }
        printf("%s", after);
    }
}

/*
 * Print contents of a count list (i.e., histogram).
 */
void print_counts(count_t *a, count_t n)
{
    for (count_t i = 0; i < n; i++) {
        printf("%lu ", a[i]);
    }
}

/*
 * Merge two sorted lists ("left" and "right) into "dest" using temp storage.
 */
void merge(int left[], count_t lsize, int right[], count_t rsize, int dest[])
{
    count_t dsize = lsize + rsize;
    int *tmp = (int*)malloc(sizeof(int) * dsize);
    if (tmp == NULL) {
        fprintf(stderr, "Out of memory!\n");
        exit(EXIT_FAILURE);
    }
    count_t l = 0, r = 0;
    for (count_t ti = 0; ti < dsize; ti++) {
        if (l < lsize && (left[l] <= right[r] || r >= rsize)) {
            tmp[ti] = left[l++];
        } else {
            tmp[ti] = right[r++];
        }
    }
    memcpy(dest, tmp, dsize*sizeof(int));
    free(tmp);
}

/*
 * Generate random integers for "nums".
 * All integers are generated by p0 and then scattered to the other processes.
 */
void randomize()
{
    // p0 generates all numbers
    if (my_rank == 0) {
        srand(42);
        for (count_t i = 0; i < global_n; i++) {
            nums[i] = rand() % RMAX;
        }
    }
    // scatter to all processes
    MPI_Scatter(nums, local_n, MPI_INT,
                nums, local_n, MPI_INT, 0, MPI_COMM_WORLD);
}

/*
 * Calculate histogram based on contents of "nums".
 */
void histogram()
{
    // calculate the histogram for the numbers local to this process.
    count_t tmp[BINS];
    for (count_t i = 0; i < local_n; i++) {
        hist[nums[i] % BINS]++;
    }
    // add the histograms of all processes up at p0
    // using a tmp buffer because p0 cant reduce with its own histogram
    MPI_Reduce(hist, tmp, BINS, MPI_COUNT, MPI_SUM, 0, MPI_COMM_WORLD);
    if (my_rank == 0) {
        memcpy(hist, tmp, BINS*sizeof(count_t));
    }
}

/*
 * Shift "nums" left by the given number of slots. Anything shifted off the left
 * side should rotate around to the end, so no numbers are lost.
 */
void shift_left()
{
    // rank of the process to send to
    int dest_rank;

    // preserve first shift_n values
    int *tmp = (int*)malloc(sizeof(int) * shift_n);
    if (tmp == NULL) {
        fprintf(stderr, "Out of memory!\n");
        exit(EXIT_FAILURE);
    }
    for (count_t i = 0; i < shift_n; i++) {
        tmp[i] = nums[i];
    }

    // perform shift
    for (count_t i = 0; i < local_n-shift_n; i++) {
        nums[i] = nums[(i + shift_n) % local_n];
    }

    // "rotate" first shift_n values around to the next process
    dest_rank = (nprocs + my_rank - 1) % nprocs;
    MPI_Sendrecv(tmp,                            shift_n, MPI_INT, dest_rank,      0,
                 &nums[local_n - shift_n], shift_n, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG,
                 MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    free(tmp);
}

/*
 * Sort "nums" using the mergesort algorithm.
 */
void merge_sort()
{
    // Bitwise operation to get the next level/where we send our information to
    unsigned int next_level = (my_rank-1) & my_rank;

    // Current level is the number of nodes in the binomial tree 
    // Should be the right most 1 bit of my_rank followed by all less-significant zeros
    // The number of zeros in current_level is the number of receives
    unsigned int current_level = my_rank ^ next_level;
    // Rank 0 needs a level of nprocs as that is how many nodes are in the tree with root 0
    if (my_rank == 0) current_level = nprocs;

    int num_recv = local_n; // number of elements received
    qsort(nums, local_n, sizeof(int), cmp);
    int *tmp = malloc(global_n * sizeof(int));
    // for each child, starting with the leaf child
    for (unsigned int i = 1; i < current_level; i = i << 1) {
	int recv_size = i * local_n; // number of elements to be received
        int source = i | my_rank;    // source node
	// fprintf(stderr, "%d waiting for %d items from %d\n", my_rank, recv_size, source);

        // receive child's array into tmp
        MPI_Recv(tmp, recv_size, MPI_INT, source, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        merge(tmp, recv_size, nums, num_recv, nums); // Merge nums/information recv
        num_recv+= i*local_n; // add elements received to count
    }
    free(tmp);
    // fprintf(stderr, "%d sending %lu items to %d, lvl: %d\n",
    //         my_rank, local_n*current_level, next_level, current_level);

    // send local array to the parent
    if (my_rank != 0) MPI_Send(nums, local_n*current_level, MPI_INT, next_level, 0, MPI_COMM_WORLD);

}

int main(int argc, char *argv[])
{
    // MPI Initialization
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);
    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);

    if (!parse_command_line(argc, argv)) {
        exit(EXIT_FAILURE);
    }

    local_n = global_n / nprocs;
    initialize_data_structures();

    // initialize random numbers
    START_TIMER(rand)
    randomize();
    STOP_TIMER(rand)

    if (global_n <= MAX_DEBUG_COUNT) {
        print_distributed_nums(nums, local_n,
                               "\nDEBUG original list: ",
                               "\n");
    }

    // compute histogram
    START_TIMER(hist)
    histogram();
    STOP_TIMER(hist)

    // perform left shift
    START_TIMER(shft)
    shift_left();
    STOP_TIMER(shft)

    if (global_n <= MAX_DEBUG_COUNT) {
        print_distributed_nums(nums, local_n,
                               "DEBUG shifted list:  ",
                               "\n");
    }

    // perform merge sort
    START_TIMER(sort)
    merge_sort();
    STOP_TIMER(sort)

    // print final results
    if (global_n <= MAX_DEBUG_COUNT && my_rank == 0) {
	printf("DEBUG sorted list:   ");
	print_nums(nums, global_n);
	printf("\n");
    }
    if (my_rank == 0) {
        printf("HISTOGRAM: ");
        print_counts(hist, BINS);
        printf("  RAND: %7.4f  HIST: %7.4f  SHFT: %7.4f  SORT: %7.4f\n",
                GET_TIMER(rand), GET_TIMER(hist), GET_TIMER(shft), GET_TIMER(sort));
	// fprintf(stderr, "I'm running with %d processes.\n", nprocs);
    }

    // clean up and exit
    MPI_Finalize();
    free(nums);
    free(hist);
    return EXIT_SUCCESS;
}
